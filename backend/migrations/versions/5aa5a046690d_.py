"""empty message

Revision ID: 5aa5a046690d
Revises: 
Create Date: 2025-03-13 15:46:17.543663

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '5aa5a046690d'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('transactions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('type', sa.String(length=10), nullable=False),
    sa.Column('category', sa.String(length=50), nullable=False),
    sa.Column('amount', sa.Float(), nullable=False),
    sa.Column('date', sa.Date(), nullable=False),
    sa.Column('description', sa.String(length=256), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('investment_transactions', schema=None) as batch_op:
        batch_op.drop_index('idx_invtrx_user')

    op.drop_table('investment_transactions')
    op.execute("DROP TABLE categories CASCADE")
    with op.batch_alter_table('recommendations', schema=None) as batch_op:
        batch_op.drop_index('idx_reco_user')

    op.drop_table('recommendations')
    with op.batch_alter_table('financial_transactions', schema=None) as batch_op:
        batch_op.drop_index('idx_fintrx_category')
        batch_op.drop_index('idx_fintrx_user')

    op.drop_table('financial_transactions')
    with op.batch_alter_table('investment_instruments', schema=None) as batch_op:
        batch_op.drop_index('idx_instrument_user')

    op.drop_table('investment_instruments')
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('name', sa.String(length=128), nullable=False))
        batch_op.alter_column('email',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=128),
               existing_nullable=False)
        batch_op.alter_column('password_hash',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=256),
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('now()'))
        batch_op.drop_column('updated_at')
        batch_op.drop_column('first_name')
        batch_op.drop_column('last_name')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('last_name', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('first_name', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False))
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('password_hash',
               existing_type=sa.String(length=256),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
        batch_op.alter_column('email',
               existing_type=sa.String(length=128),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
        batch_op.drop_column('name')

    op.create_table('investment_instruments',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('investment_instruments_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('instrument_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('symbol', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('instrument_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='fk_instruments_user', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='investment_instruments_pkey'),
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('investment_instruments', schema=None) as batch_op:
        batch_op.create_index('idx_instrument_user', ['user_id'], unique=False)

    op.create_table('financial_transactions',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('category_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('amount', sa.NUMERIC(precision=14, scale=2), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('transaction_date', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['category_id'], ['categories.id'], name='fk_fintrx_category', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='fk_fintrx_user', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='financial_transactions_pkey')
    )
    with op.batch_alter_table('financial_transactions', schema=None) as batch_op:
        batch_op.create_index('idx_fintrx_user', ['user_id'], unique=False)
        batch_op.create_index('idx_fintrx_category', ['category_id'], unique=False)

    op.create_table('recommendations',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('instrument_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('recommendation_text', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('confidence_score', sa.NUMERIC(precision=5, scale=2), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['instrument_id'], ['investment_instruments.id'], name='fk_reco_instrument', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='fk_reco_user', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='recommendations_pkey')
    )
    with op.batch_alter_table('recommendations', schema=None) as batch_op:
        batch_op.create_index('idx_reco_user', ['user_id'], unique=False)

    op.create_table('categories',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='fk_cat_user', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='categories_pkey')
    )
    op.create_table('investment_transactions',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('instrument_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('transaction_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('total_amount', sa.NUMERIC(precision=14, scale=2), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('transaction_date', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('note', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['instrument_id'], ['investment_instruments.id'], name='fk_trx_instrument', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='fk_trx_user', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='investment_transactions_pkey')
    )
    with op.batch_alter_table('investment_transactions', schema=None) as batch_op:
        batch_op.create_index('idx_invtrx_user', ['user_id'], unique=False)

    op.drop_table('transactions')
    # ### end Alembic commands ###
